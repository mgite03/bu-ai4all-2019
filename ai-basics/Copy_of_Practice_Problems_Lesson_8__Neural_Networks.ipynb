{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Practice Problems - Lesson 8_ Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgite03/bu-ai4all-2019/blob/main/ai-basics/Copy_of_Practice_Problems_Lesson_8__Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOeLiXAfUc7g"
      },
      "source": [
        "# Practice Problems\n",
        "## Lesson 8: Neural Networks\n",
        "---\n",
        "Created by Terron Ishihara"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mggjIxKJUgiZ"
      },
      "source": [
        "### Practice Problem\n",
        "\n",
        "Let's explore neural networks using scikit-learn's Multi-layer Perceptron (basically another name for a neural net). Naturally, we will use the MNIST hand-written digits dataset, which is essentially the \"hello world\" example for neural network classification.\n",
        "\n",
        "> Start by importing the dataset. This may take a little while since the dataset is a little larger than the ones we've used in past problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXSQNTytZSi9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "X = X / X.max()\n",
        "\n",
        "# Partition the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tixhW2hudJSV"
      },
      "source": [
        "> Each data point is a 28x28 matrix of grayscale values. Let's visualize this by plotting these values, using the first digit as an example. Feel free to change the index into X to see what other digits are in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1_0Ye0bMsb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "2e92b835-bd96-4eea-83ac-4a45d16c2a48"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.gray() \n",
        "\n",
        "# Since each data point is stored in a list of 784 values, we have\n",
        "# to reshape the list into a 28x28 array.\n",
        "digit = X[0].reshape(28,28)\n",
        "plt.matshow(digit)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBACBQgAQ/g86lECXzHqBpgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Lazd03d5ee"
      },
      "source": [
        "> Now we can initialize the classifier, train it, and observe how well the classifier works on our test set. \n",
        "\n",
        "> The `hidden_layer_sizes` parameter accepts a tuple that specifies the number of hidden layers and the number of neurons per layer. The `solver` parameter specifies that we'll use Stochastic Gradient Descent.\n",
        "\n",
        "> * `hidden_layer_sizes`: The number of hidden layers and number of neurons per layer. For example, the tuple (64, 32, 16) represents 3 hidden layers, with 64, 32, and 16 neurons, respectively.\n",
        "> * `solver`: The solver for weight optimization. We learned about Stochastic Gradient Descent, so we use that here.\n",
        "> * `activation`: The activation function for the hidden layers. Possible values are `'identity'`, `'logistic'`, `'tanh'`, and `'relu'`.\n",
        "> * `max_iter`: The maximum number of iterations (updates) to perform. Ideally, the weights will converge, meaning the updates hardly change the weights. Keeping this value low will prevent the code from taking a long time (but may sacrifice accuracy).\n",
        "\n",
        "> The setup provided below is not very accurate at predicting on the test set. Go ahead and run the code to see the resulting score. \n",
        "\n",
        "> Try changing the parameters for the classifier and see how it affects the score. (`solver` needn't be changed since stochastic gradient descent is the only solver we learned about.) For example, which activation function that we mentioned in the lesson may be very effective?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muzgZTffeAEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ddb2f21-d5d9-4604-9dc4-ee8d4eeaf39d"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize the classifier\n",
        "mlp_clf = MLPClassifier(\n",
        "    hidden_layer_sizes=(6,), \n",
        "    solver='sgd', \n",
        "    activation='relu',\n",
        "    max_iter=5\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the mean accuracy on the test data and print it\n",
        "score = mlp_clf.score(X_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7532571428571428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}